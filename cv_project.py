# -*- coding: utf-8 -*-
"""CV PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n-ofz8OFc_9QX--sKR3sOPM7WyiPTIKQ
"""

import numpy as np
import cv2
import mediapipe as mp
import pyautogui
import screen_brightness_control as sbc
import webbrowser
import os

# Initialize variables
x1 = y1 = x2 = y2 = last_x = last_y = 0
browser_opened = False
is_muted = False

# Thresholds
volume_control_distance_threshold = 50
brightness_control_distance_threshold_high = 100
brightness_control_distance_threshold_low = 50
swipe_threshold = 100

# Start webcam
webcam = cv2.VideoCapture(0)

# MediaPipe hands initialization
mp_hands = mp.solutions.hands
hands_detector = mp_hands.Hands()
drawing_utils = mp.solutions.drawing_utils

while True:
    success, image = webcam.read()
    if not success:
        break

    frame_height, frame_width, _ = image.shape
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    output = hands_detector.process(rgb_image)
    hands = output.multi_hand_landmarks

    if hands:
        for hand in hands:
            drawing_utils.draw_landmarks(image, hand)
            landmarks = hand.landmark

            wrist_x = int(landmarks[0].x * frame_width)
            hand_side = "Right" if wrist_x >= frame_width / 2 else "Left"

            for id, landmark in enumerate(landmarks):
                x = int(landmark.x * frame_width)
                y = int(landmark.y * frame_height)

                # Index fingertip
                if id == 8:
                    cv2.circle(image, (x, y), 8, (0, 255, 255), -1)
                    x1, y1 = x, y

                    if last_x != 0:
                        delta_x = x - last_x
                        if abs(delta_x) > swipe_threshold:
                            if delta_x > 0:
                                pyautogui.hotkey('ctrl', 'tab')
                                cv2.putText(image, "Next Tab", (10, 350), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                            else:
                                pyautogui.hotkey('ctrl', 'shift', 'tab')
                                cv2.putText(image, "Previous Tab", (10, 350), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    last_x = x

                # Thumb tip
                if id == 4:
                    cv2.circle(image, (x, y), 8, (0, 0, 255), -1)
                    x2, y2 = x, y

            # Distance between thumb and index finger
            dist = ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5
            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)

            if hand_side == "Left":
                # Brightness control
                try:
                    current_brightness = sbc.get_brightness(display=0)[0]
                    if dist > brightness_control_distance_threshold_high:
                        new_brightness = min(current_brightness + 10, 100)
                        sbc.set_brightness(new_brightness)
                        cv2.putText(image, "Brightness Up", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    elif dist < brightness_control_distance_threshold_low:
                        new_brightness = max(current_brightness - 10, 0)
                        sbc.set_brightness(new_brightness)
                        cv2.putText(image, "Brightness Down", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                except:
                    pass

            elif hand_side == "Right":
                # Browser gesture: all 4 fingers up
                if not browser_opened:
                    if all(landmarks[i].y < landmarks[0].y for i in range(1, 5)):
                        webbrowser.open("https://www.google.com")
                        browser_opened = True
                        cv2.putText(image, "Opening Browser", (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

                # Volume control
                if dist > volume_control_distance_threshold:
                    pyautogui.press("volumeup")
                    cv2.putText(image, "Volume Up", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                else:
                    pyautogui.press("volumedown")
                    cv2.putText(image, "Volume Down", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

                # Mute gesture: middle finger above base of index
                if landmarks[12].y < landmarks[9].y:
                    if not is_muted:
                        os.system("nircmd mutesysvolume 1")
                        is_muted = True
                        cv2.putText(image, "Muted", (10, 300), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                else:
                    if is_muted:
                        os.system("nircmd mutesysvolume 0")
                        is_muted = False
                        cv2.putText(image, "Unmuted", (10, 300), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    # Show frame
    cv2.imshow("Hand Volume and Brightness Control", image)
    key = cv2.waitKey(10)
    if key == 27:  # ESC to exit
        break

# Cleanup
webcam.release()
cv2.destroyAllWindows()